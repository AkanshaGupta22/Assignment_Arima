---
title: "ARIMA_MODEL"
author: "Akansha Gupta"
date: "2023-11-22"
output: html_document
---

```{r}


library(fpp)
library(fpp2)
library(forecast)

library(readxl)
coffeebrazil <- read_excel("C:/Users/ag2183/Desktop/coffeebrazil.xlsx")
View(coffeebrazil)

#time series conversion 

TimeSeries<-ts(coffeebrazil$Import_value,start=c(2010,01),end=c(2022,06),frequency=12) 
head(TimeSeries)
plot(TimeSeries) 
#The time series analysis of coffee imports in Brazil from 2010 to 2022 reveals a pronounced annual seasonality, with recurring peaks in May and November. Despite some fluctuations and an outlier in June 2020, a discernible increasing trend in import values is evident over the years. The data suggests potential long-term growth in coffee imports, reflecting the resilience and adaptability of the market.


ndiffs(TimeSeries)

tsdisplay(TimeSeries)
timeseriesdiff1 <- diff(TimeSeries, differences=1)
plot(timeseriesdiff1)
tsdisplay(timeseriesdiff1)

#Based on the provided results for the ACF, PACF, and the differenced series `timeseriesdiff1`, let's assess the stationarity and identify any autocorrelation or seasonality:
#Stationarity Assessment: 
#The original time series `TimeSeries` had a differencing order of 0 (`ndiffs(TimeSeries) = 0`), suggesting that no differencing was initially required.
#After differencing (`timeseriesdiff1`), the ACF and PACF plots show a significant reduction in autocorrelation at various lags, indicating the achievement of stationarity.
#Autocorrelation and Seasonality:
#The ACF and PACF plots of `timeseriesdiff1` exhibit autocorrelation patterns that decay after the initial lags, suggesting a lack of strong autocorrelation in the differenced series.
#Some spikes at lags 12 and 24 in the ACF and PACF may imply residual seasonality. However, these values are relatively low and could be considered noise.
#Conclusion:
#Differencing was performed on the original time series, but the resulting `timeseriesdiff1` appears to be sufficiently stationary.
#The autocorrelation and partial autocorrelation values suggest that the differenced series is suitable for modeling and forecasting purposes.
#it seems that the original time series `TimeSeries` did not require differencing for stationarity, but the differenced series `timeseriesdiff1` is appropriate for further modeling and forecasting analyses. Consider exploring time series models like ARIMA on the differenced series for accurate predictions.

#Q1: Explain the output?
auto_fit <- auto.arima(TimeSeries, trace=TRUE, stepwise = FALSE)
auto_fit

#Here's a breakdown of the result:
#ARIMA Order (p, d, q): (3, 0, 0): The autoregressive component (AR) involves three lag terms. The differencing component (I) is set to 0, indicating that the time series is stationary without differencing. The moving average component (MA) involves zero lag terms.
#Seasonal Order (P, D, Q)[12]: (1, 0, 0): The seasonal autoregressive component (SAR) involves one lag term. The seasonal differencing component (SI) is set to 0, indicating no seasonal differencing. The seasonal moving average component (SMA) involves zero lag terms.
#Mean: The model includes a non-zero mean term of approximately 111,649.245.
#The AutoARIMA analysis on the time series data of coffee imports in Brazil suggests that the best-fitting model is ARIMA(3,0,0)(1,0,0)[12] with a non-zero mean. The chosen ARIMA model suggests that the three lagged autoregressive terms (AR) and one seasonal autoregressive term (SAR) at a 12-month interval, along with a non-zero mean, suggesting that past values and seasonality play a role in predicting future coffee import data. The coefficients of the model, such as ar1, ar2, ar3, sar1, and mean, provide insights into the strength and nature of these relationships. The variance of the error term is around 457,299,099. The statistical measures AIC (3425.36), AICc (3425.95), and BIC (3443.43) indicate the goodness of fit, with lower values suggesting a better fit. The AIC values indicate that this model is a reasonable choice among the tested models, considering the trade-off between goodness of fit and model complexity. It's essential to note that the appropriateness of the model should also be assessed based on diagnostic checks, such as residuals analysis, to ensure that the model adequately captures the characteristics of the data and that the residuals exhibit no discernible patterns.

attributes(auto_fit)

#Q3:Perform and Plot the forecast for the next five periods?
plot(forecast(auto_fit,h=5,level=c(99.5)))

#The forecast generated by the ARIMA(3,0,0)(1,0,0)[12] model with a non-zero mean for the next five months (July 2022 to November 2022) indicates varying trends in coffee imports for Brazil.The forecasted values show fluctuations in coffee import volumes over the specified period, indicating potential underlying trends or seasonality in the market.The forecast suggests a peak in July at 131,567.4 metric tons, followed by a surge in August to 151,324.2 metric tons. However, a dip is expected in September (125,843.0 metric tons) before rebounding in October (137,532.6 metric tons). A decline is forecasted for November, with an estimated volume of 124,381.1 metric tons. The prediction intervals at a 99.5% confidence level offer a measure of uncertainty. 

Acf(TimeSeries)
Acf(timeseriesdiff1)

#The autocorrelation function (ACF) for the original time series 'TimeSeries' exhibits a strong positive correlation at lag 1 (0.759), indicating a significant relationship between consecutive observations. The correlation gradually decreases with increasing lags, turning negative after lag 15. The presence of autocorrelation suggests a potential seasonality pattern. After differencing the time series once ('timeseriesdiff1'), the ACF for the differenced series shows a spike at lag 1 (-0.264), indicating successful removal of the first-order autocorrelation. The subsequent autocorrelations, while fluctuating, generally do not exhibit a clear pattern, suggesting that the differencing has helped make the time series more stationary. These results provide insights for selecting appropriate parameters in time series models, such as ARIMA, to capture the underlying patterns and seasonality in the data.

#Residual Analysis
Acf(auto_fit$residuals)
Box.test(residuals(auto_fit), lag=20, type="Ljung")
plot.ts(residuals(auto_fit))
hist(auto_fit$residuals)
# Open a new plotting device with adjusted size
windows(width = 10, height = 8)
# Plot the time series diagnostics
tsdiag(auto_fit)



#seasonal data
nsdiffs(TimeSeries) 
#This command is used to determine the number of seasonal differences required to stationarize the time series TimeSeries. The result is 0, suggesting that no seasonal differencing is needed.
ndiffs(TimeSeries)
# This command calculates the number of differences needed to stationarize the time series without considering seasonality. The result is 0, indicating that no differencing is required for the non-seasonal component.
ndiffs((diff(TimeSeries,4)))
tsdisplay(diff(diff(TimeSeries,4))) #not required, added just to check the difference in stationarity

fit3 <- auto.arima(TimeSeries,trace=TRUE, stepwise = FALSE )
fit3
#The ARIMA(3,0,0)(1,0,0)[12] time series model, selected for coffee data, reveals a significant seasonal pattern with a 12-month cycle. The autoregressive coefficients indicate a notable influence of the past three observations, while the seasonal autoregressive term suggests a consistent pattern every 12 months. The estimated mean of 111,649.245 represents the average level of the time series. The model, chosen based on its minimized AIC, demonstrates a good fit to the data, but it is crucial to validate its performance using out-of-sample data and inspect residuals for any remaining patterns.

#Residual Analysis
Acf(fit3$residuals)
Box.test(residuals(fit3), lag=20, type="Ljung")
plot.ts(residuals(fit3))
hist(fit3$residuals)
windows(width = 10, height = 8)
tsdiag(fit3)

#The residual analysis of the time series data reveals several key insights. The autocorrelation function (ACF) plot of the residuals, obtained using `Acf(fit3$residuals)`, shows that there is no significant autocorrelation in the residuals, as most autocorrelations are close to zero. This is further supported by the Box-Ljung test (`Box.test(residuals(fit3), lag=20, type="Ljung")`), which yields a test statistic of 10.116 with 20 degrees of freedom and a p-value of 0.966. The high p-value suggests that there is no evidence to reject the null hypothesis of no autocorrelation in the residuals up to lag 20. Additionally, the time series plot (`plot.ts(residuals(fit3))`) does not reveal any apparent patterns or trends in the residuals over time. The histogram (`hist(fit3$residuals)`) illustrates that the distribution of residuals is roughly symmetric with a peak around zero, although there is a noticeable long left tail. Overall, these findings indicate that the model's residuals exhibit no significant autocorrelation and are approximately normally distributed, suggesting that the model adequately captures the underlying patterns in the time series data.

#Q4. Show the accuracy of your ARIMA model?
accuracy(auto_fit)

#The forecasting model, represented by auto_fit, exhibits reasonably accurate predictions on the training set, as indicated by various evaluation metrics. The Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) values, at 21025.12 and 15610.6, respectively, quantify the magnitude of forecast errors, while the Mean Absolute Percentage Error (MAPE) at 14.45% provides a measure of the average percentage difference between predicted and actual values. The Mean Absolute Scaled Error (MASE) of 0.496 indicates good performance relative to a naive forecast. The Autocorrelation of Forecast Errors at Lag 1 (ACF1) is -0.016, suggesting a limited correlation between consecutive forecast errors. Overall, the model demonstrates effective forecasting performance on the training data, capturing patterns and minimizing errors.


```


